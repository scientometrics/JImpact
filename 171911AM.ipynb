{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scopus Authors\n",
    "### This is an academic project for authors data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import mysql.connector\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from itertools import cycle\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MySql connector\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"shahab\",\n",
    "    database=\"j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check the database connection\n",
    "if mydb:\n",
    "    print(\"connected\")\n",
    "else:\n",
    "    print(\"NOT connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor = mydb.cursor()\n",
    "df = pd.read_csv(\"authors.csv\") #authors CSV file\n",
    "df = df.dropna(axis=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique() # we have 281465 unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### authors dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_array = df.loc[1229:281465, \"author_id\"].values\n",
    "authors_list = authors_array.tolist()\n",
    "print(len(authors_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user agent dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ua = pd.read_csv(\"ua.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = []\n",
    "a = df_ua.values.tolist()\n",
    "for i in a:\n",
    "    k.append(i[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useragents = cycle(k)\n",
    "authorsids = cycle(authors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_no = []   # list of ids which are not in Scopus website\n",
    "z = 0  \n",
    "print(datetime.datetime.now())\n",
    "while True:\n",
    "    auth = next(authorsids)\n",
    "    url = \"https://www.scopus.com/authid/detail.uri?authorId={}\".format(auth)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url,headers={'User-Agent': next(useragents)})\n",
    "        print(\"Request Successful\")\n",
    "        print(datetime.datetime.now())\n",
    "    except:\n",
    "        ids_no.append(auth)\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "        \n",
    "\n",
    "    while True:\n",
    "        response = requests.get(url,headers={'User-Agent': next(useragents)})\n",
    "        page_soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        first = page_soup.findAll(\"h2\", {\"class\" : \"wordBreakWord\"})\n",
    "        if len(first) > 0:\n",
    "            full_name = first[0].text.replace(\",\\xa0\", \" \").replace(\"\\r\", \" \").replace(\"Is this you? Claim profile  Opens in new window\", \" \").strip()\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "                                \n",
    "            \n",
    "                    \n",
    "         \n",
    "        \n",
    "\n",
    "    try:\n",
    "        other_names = page_soup.findAll(\"div\", {\"id\" : \"otherNameFormatBadges\"})\n",
    "        span_list = other_names[0].findAll(\"span\")\n",
    "        other_names = []\n",
    "        for i in span_list:\n",
    "            other_names.append(i.text.strip())\n",
    "        others = \"|\".join(other_names).replace(\"|\", \"| \") \n",
    "        t = len(other_names)\n",
    "    except:\n",
    "        others= \"NA\"\n",
    "        t = 0\n",
    "\n",
    "\n",
    "    try:\n",
    "        university = page_soup.findAll(\"div\", {\"class\" : \"authAffilcityCounty\"})[0].text.strip().replace(\"\\r\", \" \")\n",
    "    except:\n",
    "        university = \"NA\"\n",
    "\n",
    "    try:\n",
    "        subject_areas = page_soup.findAll(\"span\", {\"class\" : \"badges\"})\n",
    "        subject_areas = subject_areas[t:]\n",
    "\n",
    "\n",
    "        areas = []\n",
    "        for i in range(len(subject_areas)):\n",
    "             areas.append(subject_areas[i].text.strip().replace(\",\", \"\"))\n",
    "\n",
    "        subjects = \",\".join(areas).replace(\",\", \", \")\n",
    "    except:\n",
    "        subjects=\"NA\"\n",
    "\n",
    "    try:\n",
    "        documents_by_author = page_soup.findAll(\"span\", {\"class\" : \"fontLarge pull-left\"})[0].text\n",
    "        if len(documents_by_author) > 0:\n",
    "            pass\n",
    "        else:\n",
    "            documents_by_author = 0\n",
    "    except:\n",
    "        Documnets_by_author = 0\n",
    "\n",
    "    try:\n",
    "        total_citation_number = page_soup.findAll(\"span\", {\"class\" : \"fontLarge darkGrayText\"})[0].text\n",
    "        if len(total_citation_number) > 0:\n",
    "            pass\n",
    "        else:\n",
    "            total_citation_number = 0\n",
    "    except:\n",
    "        total_citation_number = 0\n",
    "\n",
    "    try:\n",
    "        total_document = page_soup.findAll(\"div\", {\"class\" : \"lightGreyText\"})[0].findAll(\"span\")[1].text\n",
    "        if len(total_document) > 0:\n",
    "            pass\n",
    "        else:\n",
    "            total_document = 0\n",
    "        \n",
    "    except:\n",
    "        total_document = 0\n",
    "\n",
    "    try:\n",
    "        h_index = page_soup.select(\"span[class='fontLarge']\")[0].text\n",
    "        \n",
    "\n",
    "    except:\n",
    "        h_index = 0\n",
    "\n",
    "    sql = \"\"\"INSERT INTO authors_end(author_id, full_name, others, university, subjects, document_by_author, total_citation_number, total_document, h_index) VALUES (\n",
    "    \"{}\",\"{}\", \"{}\", \"{}\", \"{}\", \"{}\", \"{}\", \"{}\", \"{}\")\"\"\".format(str(auth), full_name, others, university, subjects, int(documents_by_author),\n",
    "                                                           int(total_citation_number), int(total_document), int(h_index))\n",
    "    \n",
    "\n",
    "    try:\n",
    "        mycursor.execute(sql)\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        mydb.rollback()\n",
    "        print(\"NOT connected\")\n",
    "    z += 1\n",
    "    print(\"we have collected: {} number(s) so far\".format(z))\n",
    "    if auth == authors_list[-1]:\n",
    "        break\n",
    "    else:\n",
    "        pass\n",
    "    time.sleep(5) # 5 seconds sleep\n",
    "print(\"finished\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehs",
   "language": "python",
   "name": "ehs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
