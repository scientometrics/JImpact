{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this is the module for extracting IPs and User Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserAgent():\n",
    "    \"\"\"for extracting user agents\"\"\"\n",
    "    def __init__(self, url=\"www.useragentstring.com/pages/useragentstring.php?name=All\"):\n",
    "        self.url = url\n",
    "        self.list = []\n",
    "    def get_list(self):\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'})\n",
    "        time.sleep(6)\n",
    "        page_soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        search = page_soup.findAll(\"a\")\n",
    "        for i in range(5,len(search) - 2):\n",
    "            if \"/\" in search[i].text:\n",
    "                self.list.append(search[i].text)\n",
    "        return self.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ip():\n",
    "    \"\"\"for extracting ips\"\"\"\n",
    "    def __init__(self, url=\"https://free-proxy-list.net/\"):\n",
    "        self.url = url\n",
    "        self.set = {}\n",
    "        self.list = []\n",
    "    def get_ip(self):\n",
    "        response = requests.get(self.url, headers={'User-Agent': 'Mozilla/5.0 (compatible; U; ABrowse 0.6; Syllable) AppleWebKit/420+ (KHTML, like Gecko)'})\n",
    "        time.sleep(6)\n",
    "        page_soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        search = page_soup.findAll(\"tr\")\n",
    "        search_want = search[1:301]\n",
    "        for tr in search_want:\n",
    "#             print(self.list)\n",
    "            tdd = tr.findAll(\"td\")\n",
    "            if tdd[-2].text == \"yes\":\n",
    "                if tdd[4].text == \"elite proxy\":\n",
    "                    value =  \"http://\" + tdd[0].text + \":\" + tdd[1].text\n",
    "                    self.list.append(value)\n",
    "                    \n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "        return self.list\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watch",
   "language": "python",
   "name": "watch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
